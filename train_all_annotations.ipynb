{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ca67a98b-5afc-4696-a1ea-00f0332e22c0",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on November 22, 2022\n",
    "\n",
    "The following things are implemented:\n",
    "    - Kfold cross validation avg\n",
    "    - Stop training when no improvement\n",
    "    \n",
    "To implement:\n",
    "    - Use network to crop the fish out (will need to change dataset.py, transform fct will be different for every img)\n",
    "    \n",
    "Things to think about:\n",
    "    - Decrease LR \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675f8cd2-ca88-4270-9f0c-dbde255ac70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import dataset_all_annotations as dataset\n",
    "import metrics\n",
    "import time\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import loss_fn_multiclass as loss_fn\n",
    "from unet import UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce6a499-b4c6-461d-b818-7846c74ba0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, image, device, transform, out_threshold=0.5):\n",
    "    with torch.no_grad():\n",
    "        x = image\n",
    "        logits = model(x.to(device))\n",
    "        logits = transform(logits)\n",
    "        y_pred = nn.Softmax(dim=1)(logits)\n",
    "        proba = y_pred.detach().cpu().squeeze(0).numpy()[1, :, :]\n",
    "        return proba > out_threshold\n",
    "    \n",
    "def stack_masks(masks, batch, classes, size=(512,512)):\n",
    "    stacks = []\n",
    "    tr = transforms.ToTensor()\n",
    "    m_size = masks.shape\n",
    "    #print(masks.shape)\n",
    "    for b in range(m_size[0]):\n",
    "        #print(\"B:\", b)\n",
    "        m = np.zeros(size)\n",
    "        m = tr(m)\n",
    "        for c in range(m_size[1]):\n",
    "            #print(\"C:\", c)\n",
    "            m = torch.where(m==0, masks[b,c,:,:]*(c+1),m)\n",
    "        m = m.squeeze()\n",
    "        stacks.append(m)\n",
    "    \n",
    "    stacks = tuple(stacks)\n",
    "    stacks = torch.stack(stacks, 0)\n",
    "    return stacks\n",
    "\n",
    "def validate(model, validation_loader, transform, DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for images, masks, names in validation_loader:\n",
    "            images = transform(images)\n",
    "            outputs = model(images.to(DEVICE))\n",
    "            #outputs = untransform(outputs)\n",
    "\n",
    "            masks = masks.type(torch.LongTensor)\n",
    "            masks = transform(masks)\n",
    "            masks = torch.squeeze(masks, 1)\n",
    "            masks = stack_masks(masks, cst.BATCH_SIZE, 25, size=(512,512))\n",
    "\n",
    "            vloss = criterion(outputs, masks.to(torch.int64).to(DEVICE))\n",
    "            loss = vloss.detach().item()\n",
    "            val_loss.append(loss)\n",
    "\n",
    "        loss = np.mean(val_loss)\n",
    "        # print(\"Validation loss before training: {}\".format(loss))\n",
    "    return loss\n",
    "\n",
    "def train(model, training_loader, transforms, DEVICE, criterion, optimiser):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for images, masks, names in training_loader:\n",
    "        images = transform(images)\n",
    "        outputs = model(images.to(DEVICE))\n",
    "        #outputs = untransform(outputs)\n",
    "\n",
    "        masks = masks.type(torch.LongTensor)\n",
    "        masks = transform(masks)\n",
    "        masks = torch.squeeze(masks, 1)\n",
    "        masks = stack_masks(masks, cst.BATCH_SIZE, 25, size=(512,512))\n",
    "\n",
    "        tloss = criterion(outputs, masks.to(torch.int64).to(DEVICE))\n",
    "        loss = tloss.detach().item()\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        tloss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    loss = np.mean(train_loss)\n",
    "    return loss\n",
    "\n",
    "def evaluate(eval_model, testing_loader):\n",
    "    tps = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    IOUs = []\n",
    "\n",
    "    eval_model.eval()\n",
    "    for image, mask, name in testing_loader:\n",
    "        prediction = predict_img(eval_model, transform(image), DEVICE, untransform, out_threshold=cst.THRESHOLD)\n",
    "        pred = torch.from_numpy(prediction)\n",
    "\n",
    "        precisions.append(metrics.precision(pred, mask))\n",
    "        recalls.append(metrics.recall(pred, mask))\n",
    "        F1s.append(metrics.F1Score(pred, mask))\n",
    "        IOUs.append(metrics.IOUScore(pred, mask))\n",
    "    return precisions, recalls, F1s, IOUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1daa487d-8238-4d14-9f01-19efc9e66b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "TERMS = [\"p\"]\n",
    "SIZE = (384, 512)\n",
    "FOLDS = [0]    # 0 to 4 only a few folds at a time here for computational resources limit\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca03dfa7-4f41-40c0-92a0-0179d809b512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting term: p\n",
      "Starting fold: 0\n",
      "125\n",
      "Training set length: 84\n",
      "125\n",
      "Validation set length: 21\n",
      "125\n",
      "Testing set length: 20\n",
      "Loss used: Focal\n",
      "Epoch: 1\n",
      "Validation: 101.79570134480794.\n",
      "Best validation: 101.79570134480794.\n",
      "Epoch: 2\n",
      "Validation: 101.43583170572917.\n",
      "Best validation: 101.43583170572917.\n",
      "Epoch: 3\n",
      "Validation: 101.08918126424153.\n",
      "Best validation: 101.08918126424153.\n",
      "Epoch: 4\n",
      "Validation: 100.78871663411458.\n",
      "Best validation: 100.78871663411458.\n",
      "Epoch: 5\n",
      "Validation: 100.66330973307292.\n",
      "Best validation: 100.66330973307292.\n",
      "Epoch: 6\n",
      "Validation: 100.54517491658528.\n",
      "Best validation: 100.54517491658528.\n",
      "Epoch: 7\n",
      "Validation: 100.52655537923177.\n",
      "Best validation: 100.52655537923177.\n",
      "Epoch: 8\n",
      "Validation: 100.50945281982422.\n",
      "Best validation: 100.50945281982422.\n",
      "Epoch: 9\n",
      "Validation: 100.46764500935872.\n",
      "Best validation: 100.46764500935872.\n",
      "Epoch: 10\n",
      "Validation: 100.45563379923503.\n",
      "Best validation: 100.45563379923503.\n",
      "Epoch: 11\n",
      "Validation: 100.51359176635742.\n",
      "Best validation: 100.45563379923503.\n",
      "Epoch: 12\n",
      "Validation: 100.45744450887044.\n",
      "Best validation: 100.45563379923503.\n",
      "Epoch: 13\n",
      "Validation: 100.42965443929036.\n",
      "Best validation: 100.42965443929036.\n",
      "Epoch: 14\n",
      "Validation: 100.50255966186523.\n",
      "Best validation: 100.42965443929036.\n",
      "Epoch: 15\n",
      "Validation: 100.44275538126628.\n",
      "Best validation: 100.42965443929036.\n",
      "Epoch: 16\n",
      "Validation: 100.42638905843098.\n",
      "Best validation: 100.42638905843098.\n",
      "Epoch: 17\n",
      "Validation: 100.43686930338542.\n",
      "Best validation: 100.42638905843098.\n",
      "Epoch: 18\n",
      "Validation: 100.41835149129231.\n",
      "Best validation: 100.41835149129231.\n",
      "Epoch: 19\n",
      "Validation: 100.42659505208333.\n",
      "Best validation: 100.41835149129231.\n",
      "Epoch: 20\n",
      "Validation: 100.46601104736328.\n",
      "Best validation: 100.41835149129231.\n",
      "Epoch: 21\n",
      "Validation: 100.4134292602539.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 22\n",
      "Validation: 100.4223861694336.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 23\n",
      "Validation: 100.4364242553711.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 24\n",
      "Validation: 100.41852442423503.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 25\n",
      "Validation: 100.4250971476237.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 26\n",
      "Validation: 100.42811330159505.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 27\n",
      "Validation: 100.4213040669759.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 28\n",
      "Validation: 100.4423599243164.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 29\n",
      "Validation: 100.47103373209636.\n",
      "Best validation: 100.4134292602539.\n",
      "Epoch: 30\n",
      "Validation: 100.40575663248698.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 31\n",
      "Validation: 100.45394643147786.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 32\n",
      "Validation: 100.4760971069336.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 33\n",
      "Validation: 100.4309819539388.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 34\n",
      "Validation: 100.45537821451823.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 35\n",
      "Validation: 100.48245620727539.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 36\n",
      "Validation: 100.44870503743489.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 37\n",
      "Validation: 100.48375701904297.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 38\n",
      "Validation: 100.435302734375.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 39\n",
      "Validation: 100.43843078613281.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 40\n",
      "Validation: 100.41240946451823.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 41\n",
      "Validation: 100.49175135294597.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 42\n",
      "Validation: 100.45302073160808.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 43\n",
      "Validation: 100.4295145670573.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 44\n",
      "Validation: 100.43358484903972.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 45\n",
      "Validation: 100.45998509724934.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 46\n",
      "Validation: 100.43883768717448.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 47\n",
      "Validation: 100.44452667236328.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 48\n",
      "Validation: 100.47538248697917.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 49\n",
      "Validation: 100.48424402872722.\n",
      "Best validation: 100.40575663248698.\n",
      "Epoch: 50\n",
      "Validation: 100.44820149739583.\n",
      "Best validation: 100.40575663248698.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8zUlEQVR4nO3dd3zU9f3A8dc7ey8SVgIGkOFAVtxacVbRurWiVqy2Vm1ra4daf22xtba22tbRWusedVGtiooTRdwyBAQEWQEChIRA9rzk/fvj800IIeuSXI7k3s/HI4+7+9z3Pvf+hnDv+8yvqCrGGGNMZ4UFOwBjjDF9iyUOY4wxfrHEYYwxxi+WOIwxxvjFEocxxhi/WOIwxhjjF0scxgSJiMwTke/1cJ25InJSG89NFZG8nnw/E5oscRjjEZHLRaReRMqb/fwjSLHcIiJ1LWK5IcDvmS0i74lIpYisaisBGRMR7ACM2cd8oqrHBDsIz3Oqemkvvt8zwCfANO/neREZraqFvRiD6QOsxWH6Na/r5lcislJEdonIoyIS04V6jhKRBSJS4t0e1ey5NK/erd57vOSVp4rIqyJS6JW/KiJZPXBOZ4rIChEp9rq7DmjjuFgRecx775XAoe3UOQaYDMxU1SpVfQH4Ejivu/Ga/scShwkFlwDfBEYBY4Bf+/NiEUkDXgPuAQYAfwNeE5EB3iFPAnHAQcBA4O9eeRjwKLAfMByoArrV9eV9wD8D/BTIAOYAr4hIVCuHz8Sd8yjc+c9op+qDgPWqWtasbKlXbsweLHGYUPAPVd2sqjuB24Dp7Rx7hPdNvvHnCOB0YI2qPqmqPlV9BlgFfEtEhgCnAVer6i5VrVPV9wFUtUhVX1DVSu8D+TbgOD/ivrBFLEOBbwOvqerbqloH3AnEAke19nrgNlXdqaqbcYmvLQlASYuyEiDRj3hNiLAxDhMKNje7vxEY2s6xn7Yc4xCR47zXNbcRyASGATtVdVfLikQkDtf6OBVI9YoTRSRcVes7EfeslmMcXvJoikVVG0RksxdLS0PZ+9zbUg4ktShLAspaOdaEOGtxmFAwrNn94cBWP1+/Fdfd1NxwYAvugzlNRFJaed3PgbHA4aqaBHzDKxc/37/NWEREcOe3pZVjt7H3ubdlBTBSRJq3MCZ45cbswRKHCQU/FJEsb6zi/4Dn/Hz9HGCMiFwsIhEi8m3gQOBVVd0GvA7c5w2GR4pIY4JIxI1rFHvvPbMHzmUWcLqInCgikbjkVAN83Maxv/LiygJ+3Falqvo1sASYKSIxInIOcAjwQg/EbPoZSxwmFDwNvAWsB9YBf/DnxapaBJyB+5AuAm4AzlDVHd4h3wHqcOMeBbiBa4C7cOMPO4BPgTe6cQ6NsawGLgXu9er9FvAtVa1t5fDf4bqnNuDO/8kOqr8IyAF2AbcD59tUXNMasQs5mf5MRHKB76nqO8GOxZj+wlocxhhj/GKJwxhjjF+sq8oYY4xfrMVhjDHGLyGxADA9PV2zs7ODHYYxxvQpixYt2qGqGS3LQyJxZGdns3DhwmCHYYwxfYqItLrbgHVVGWOM8YslDmOMMX6xxGGMMcYvITHGYYzpP+rq6sjLy6O6ujrYofQbMTExZGVlERkZ2anjLXEYY/qUvLw8EhMTyc7Oxm0ObLpDVSkqKiIvL48RI0Z06jXWVWWM6VOqq6sZMGCAJY0eIiIMGDDArxacJQ5jTJ9jSaNn+fv7tMTRnqXPwYKHgx2FMcbsUyxxtGfly5Y4jDF7KCoqYuLEiUycOJHBgweTmZnZ9Li2trXLouy2cOFCrrvuug7f46ijWruE/L7DBsfbkzgYNrV2YTVjTKgaMGAAS5YsAeCWW24hISGBX/ziF03P+3w+IiJa/2jNyckhJyenw/f4+ON9+3PHWhztSRoCVbugrirYkRhj9mGXX345V199NYcffjg33HADn3/+OUceeSSTJk3iqKOOYvXq1QDMmzePM844A3BJ54orrmDq1KmMHDmSe+65p6m+hISEpuOnTp3K+eefz7hx47jkkkto3NF8zpw5jBs3jilTpnDdddc11dsbAtbiEJFHcJfbLFDVg72yNNz1nrOBXOBCVd0lIuOAR4HJwP+p6p0d1H0PcIWqJgQqfgASh7rbsnxI69w0NWNM7/ndKytYubW0R+s8cGgSM791kN+vy8vL4+OPPyY8PJzS0lI++OADIiIieOedd7j55pt54YW9L9++atUq3nvvPcrKyhg7dizXXHPNXmspvvjiC1asWMHQoUM5+uij+eijj8jJyeEHP/gB8+fPZ8SIEUyfPr3L59sVgWxxPAac2qLsJmCuqo4G5nqPAXYC1wHtJgwAEckBUnsuzHYkDna3Zdt65e2MMX3XBRdcQHh4OAAlJSVccMEFHHzwwVx//fWsWLGi1decfvrpREdHk56ezsCBA9m+fftexxx22GFkZWURFhbGxIkTyc3NZdWqVYwcObJp3UVvJ46AtThUdb6IZLcoPguY6t1/HJgH3KiqBUCBiJzeXp0iEg7cAVwMnNOT8bYqqbHFYYnDmH1RV1oGgRIfH990/ze/+Q3HH388L774Irm5uUydOrXV10RHRzfdDw8Px+fzdemY3tbbYxyDVLXxUzgfGOTn638EzG5WR2A1tjhKLXEYYzqvpKSEzMxMAB577LEer3/s2LGsX7+e3NxcAJ577rkef4/2BG1wXN0IT6evWysiQ4ELgHs7efxVIrJQRBYWFhZ2LciYFIiItRaHMcYvN9xwA7/61a+YNGlSQFoIsbGx3HfffZx66qlMmTKFxMREkpOTe/x92hLQa457XVWvNhscXw1MVdVtIjIEmKeqY5sdfwtQ3trguNeN9TDQuC5+OLBeVffvKI6cnBzt8oWc7p4ImZPh/Ee69npjTI/66quvOOCAA4IdRtCVl5eTkJCAqvLDH/6Q0aNHc/3113e5vtZ+ryKySFX3mj/c2y2O2cAM7/4M4OXOvlBVX1PVwaqararZQGVnkka3JQ21ripjzD7nwQcfZOLEiRx00EGUlJTwgx/8oNfeO5DTcZ/BDYSni0geMBO4HZglIlcCG4ELvWMHAwuBJKBBRH4KHKiqpSIyB/ieqm4NVKztShwCWxYF5a2NMaYt119/fbdaGN0RyFlVbc0PO7GVY/OBrDbqmdZGeWDXcDRKHOzGOFTBNlYzxhhbOd6hpKHgq4bq4mBHYowx+wRLHB2xKbnGGLMHSxwdSbRFgMYY05wljo7YtiPGmGaOP/543nzzzT3K7rrrLq655ppWj586dSqNywGmTZtGcXHxXsfccsst3Hln+zsuvfTSS6xcubLp8W9/+1veeecdP6PvGZY4OpI4xN1a4jDG4PaFevbZZ/coe/bZZzu1X9ScOXNISUnp0vu2TBy///3vOemkk7pUV3dZ4uhIZAzEptkYhzEGgPPPP5/XXnut6aJNubm5bN26lWeeeYacnBwOOuggZs6c2eprs7Oz2bFjBwC33XYbY8aM4Zhjjmnadh3c+oxDDz2UCRMmcN5551FZWcnHH3/M7Nmz+eUvf8nEiRNZt24dl19+Oc8//zwAc+fOZdKkSYwfP54rrriCmpqapvebOXMmkydPZvz48axatapHfgd2IafOSBxiLQ5j9kWv3wT5X/ZsnYPHw2m3t/l0Wloahx12GK+//jpnnXUWzz77LBdeeCE333wzaWlp1NfXc+KJJ7Js2TIOOeSQVutYtGgRzz77LEuWLMHn8zF58mSmTJkCwLnnnsv3v/99AH7961/z8MMP8+Mf/5gzzzyTM844g/PPP3+Puqqrq7n88suZO3cuY8aM4bLLLuNf//oXP/3pTwFIT09n8eLF3Hfffdx555089NBD3f4VWYujM5IscRhjdmveXdXYTTVr1iwmT57MpEmTWLFixR7dSi198MEHnHPOOcTFxZGUlMSZZ57Z9Nzy5cs59thjGT9+PE899VSbW7I3Wr16NSNGjGDMmDEAzJgxg/nz5zc9f+655wIwZcqUpk0Ru8taHJ2ROBjylwc7CmNMS+20DALprLPO4vrrr2fx4sVUVlaSlpbGnXfeyYIFC0hNTeXyyy+nurq644pacfnll/PSSy8xYcIEHnvsMebNm9etWBu3Ze/JLdmtxdEZiUOhogDqg78PvjEm+BISEjj++OO54oormD59OqWlpcTHx5OcnMz27dt5/fXX2339N77xDV566SWqqqooKyvjlVdeaXqurKyMIUOGUFdXx1NPPdVUnpiYSFlZ2V51jR07ltzcXNauXQvAk08+yXHHHddDZ9o6SxydkTgYtMElD2OMwXVXLV26lOnTpzNhwgQmTZrEuHHjuPjiizn66KPbfe3kyZP59re/zYQJEzjttNM49NBDm5679dZbOfzwwzn66KMZN25cU/lFF13EHXfcwaRJk1i3bl1TeUxMDI8++igXXHAB48ePJywsjKuvvrrnT7iZgG6rvq/o1rbqAKtfh2cugu+/C5lTei4wY4zfbFv1wPBnW3Ub42jHjc8vo7iqln+f6K3lKN0GmcGNyRhjgs26qtrha1CWbC62RYDGGNOMJY52jBoYz/bSGsojU0HCLXEYs48IhS723uTv79MSRztGprtLfqzfUekGyG31uDFBFxMTQ1FRkSWPHqKqFBUVERMT0+nX2BhHO/YfGA/A+sIKDrHV48bsE7KyssjLy6OwsDDYofQbMTExZGW1ei29VlniaMfwtHjCw4R1heWuxVG0NtghGRPyIiMjGTFiRLDDCGnWVdWOqIgwhqfFucSRNNRaHMYYgyWODo3KiGd9YYWbWVVdArWVwQ7JGGOCyhJHB0ZmJLB+RwUNCXZBJ2OMAUscHRqVEU+tr4FCGeAKLHEYY0KcJY4OjMpwU3JzaxNdgU3JNcaEOEscHRjpJY5VFe7WWhzGmFBniaMDafFRpMZFsrpYICrBEocxJuRZ4uiEkRkJrCvw1nJY4jDGhDhLHJ0wKiOedY1Tcm2MwxgT4gKWOETkEREpEJHlzcrSRORtEVnj3aZ65eNE5BMRqRGRX7RT51MislpElnv1RwYq/uZGZSSwo7yG2rhB1uIwxoS8QLY4HgNObVF2EzBXVUcDc73HADuB64A7O6jzKWAcMB6IBb7XU8G2p3GAfFf4ACjLB9tczRgTwgKWOFR1Pi4hNHcW8Lh3/3HgbO/YAlVdANR1UOcc9QCfA53flasbRmW4zQ63NaRCfQ1UtjwtY4wJHb09xjFIVRv7evKBQV2pxOui+g7wRjvHXCUiC0VkYXd30RyWFkdEmJBbm+QKrLvKGBPCgjY47rUautrncx8wX1U/aKf+B1Q1R1VzMjIyuvg2TmR4GPsNiGN1pa3lMMaY3k4c20VkCIB3W+BvBSIyE8gAftbDsbVrVEYCy0ri3ANLHMaYENbbiWM2MMO7PwN42Z8Xi8j3gG8C01W1oYdja9fIjAS+2BXtHtiUXGNMCAvkdNxngE+AsSKSJyJXArcDJ4vIGuAk7zEiMlhE8nCtiF97xyd5z80RkaFetffjxkU+EZElIvLbQMXf0qiMeCrrw6mPHWAtDmNMSAvYFQBVdXobT53YyrH5tDFDSlWnNbsftCsWNk7JrYweSKIlDmNMCLOV453UOCV3V/gAKN0a5GiMMSZ4LHF0UkpcFOkJUW4tR1l+sMMxxpigscThh5HpCeTWJUNFIdS3u1bRGGP6LUscfhg1MJ6vK+IBhfLtwQ7HGGOCwhKHH0amJ7Cuxls9blNyjTEhyhKHH0YNjKdAU90Dm1lljAlRljj8MCojgXxNcw8scRhjQpQlDj9kpcZREZ5EvUTYlFxjTMiyxOGH8DBhv/SE3dflMMaYEGSJw08j0xPIb0iFMmtxGGNCkyUOP40aGM9mXzJaai0OY0xossThp1EZCWxrSEVtjMMYE6IscfhpZEYC2zWVsLpyqCkLdjjGGNPrLHH4aWRGPNsap+TaIkBjTAiyxOGnpJhIqmKHuAclm4IbjDHGBIElji6IGjDc3SnJC24gxhgTBJY4uiBt8HB8hKHFm4MdijHG9DpLHF2QPTCFfE2jpmhjsEMxxpheZ4mjCw4YksgWTae6MDfYoRhjTK+zxNEF4zOT2arphJXaGIcxJvRY4uiCxJhIKmKHEF+zHRrqgx2OMcb0KkscXRSVNpxwGmwFuTEm5Fji6KKUIaMAKNqyLsiRGGNM77LE0UVZI8YAsGXj10GOxBhjepclji4aOWosAMXb1gc5EmOM6V2WOLooJj6JEknCt9PWchhjQkvAEoeIPCIiBSKyvFlZmoi8LSJrvNtUr3yciHwiIjUi8ot26hwhIp+JyFoReU5EogIVf2eUxwwmqnwbDQ0azDCMMaZXBbLF8Rhwaouym4C5qjoamOs9BtgJXAfc2UGdfwb+rqr7A7uAK3ss2i7QpGEM0gI2FFUEMwxjjOlVAUscqjoflxCaOwt43Lv/OHC2d2yBqi4A6tqqT0QEOAF4vuXrgyVuYDaZsoNlm3cFMwxjjOlVvT3GMUhVGy9ikQ8M8uO1A4BiVfV5j/OAzLYOFpGrRGShiCwsLCzsWrQdSB48knip4etcW0FujAkdQRscV1UFAjY4oKoPqGqOquZkZGQE5D3CU9326gWb1wSkfmOM2Rf1duLYLiJDALzbAj9eWwSkiEiE9zgL2NLD8fknZRgAVTs2UlffENRQjDGmt/R24pgNzPDuzwBe7uwLvRbKe8D5XXl9QCS7xDGwoYDV+Xb9cWNMaAjkdNxngE+AsSKSJyJXArcDJ4vIGuAk7zEiMlhE8oCfAb/2jk/ynpsjIkO9am8EfiYia3FjHg8HKv5OiRtAQ0SMGyDPKwlqKMYY01siOj6ka1R1ehtPndjKsfm4rqfW6pnW7P564LAeCbAniCApw8nesZO5ecVcfPjwYEdkjDEBZyvHu0mSsxgZtYslm4uDHYoxxvQKSxzdlTyMwVrImoJyqmrt2hzGmP7PEkd3JQ8jvm4nEQ01rNhq4xzGmP7PEkd3eVNyh0oRS22A3BgTAixxdJc3JXd8QglLbZzDGBMCLHF0V7KbDJaTUsGyvOLgxmKMMb3AEkd3JQ0FCeOA2BJyiyopqWxzn0ZjjOkXLHF0V3gkJA5leITbCHjZluLgxmOMMQHWqcQhIvEiEubdHyMiZ4pIZGBD60OSsxjg2w5g4xzGmH6vsy2O+UCMiGQCbwHfwV2oyQCkDCOiNI+R6fE2s8oY0+91NnGIqlYC5wL3qeoFwEGBC6uPSR4GpVuZkJlgA+TGmH6v04lDRI4ELgFe88rCAxNSH5ScBQ11HJ7hY3tpDdtLq4MdkTHGBExnE8dPgV8BL6rqChEZidvi3ACkuM0NJya5rdVtnMMY0591KnGo6vuqeqaq/tkbJN+hqtcFOLa+w1vLMTJqFxFhwheWOIwx/VhnZ1U9LSJJIhIPLAdWisgvAxtaH+KtHo8q38LBmcksyt0V5ICMMSZwOttVdaCqlgJnA68DI3AzqwxAdALEpkLxZnL2S2VJXjE1Ptsp1xjTP3U2cUR66zbOBmarah2gAYuqL0rOgpI8crLTqPU1sHyLTcs1xvRPnU0c/wZygXhgvojsB5QGKqg+KXk4lGwmJzsVgAXWXWWM6ac6Ozh+j6pmquo0dTYCxwc4tr4lZRgUbyY9PoqR6fEstMRhjOmnOjs4niwifxORhd7PX3GtD9MoOQtqy6C6hJzsVBZt3ElDg/XmGWP6n852VT0ClAEXej+lwKOBCqpP8mZWue6qNHZV1rF+R3lwYzLGmACI6ORxo1T1vGaPfyciSwIQT9+V0pg48sjZbwTgxjn2H5gYxKCMMabndbbFUSUixzQ+EJGjgarAhNRHNbY4ijczIj2eAfFRLMjdGdyYjDEmADrb4rgaeEJEkr3Hu4AZgQmpj4rPgPBoKNmEiJCTnWoD5MaYfqmzs6qWquoE4BDgEFWdBJwQ0Mj6GpGmtRwAh2ansWlnJQW24aExpp/x6wqAqlrqrSAH+FkA4unbvCm5ADnZaQAs3GitDmNM/9KdS8dKhweIPCIiBSKyvFlZmoi8LSJrvNtUr1xE5B4RWSsiy0Rkcht1TheRL71j3hCR9G6cQ89KHgYlLnEcNDSJmMgwG+cwxvQ73UkcnVmk8Bhwaouym4C5qjoamOs9BjgNGO39XAX8q2VlIhIB3A0cr6qHAMuAH3Ul+IBIHgbl28FXQ2R4GBOHpdg4hzGm32k3cYhImYiUtvJTBgztqHJVnQ+0/Mp9FvC4d/9x3P5XjeVPeCvTPwVSRGRIy5C8n3gRESAJ2NpRHL2m2ZRccOMcK7eVUlHjC2JQxhjTs9pNHKqaqKpJrfwkqmpnZ2S1NEhVt3n384FB3v1MYHOz4/K8subx1AHXAF/iEsaBwMOtvYmIXNW40r2wsLCLofqp2SJAcOMc9Q3KErs+hzGmH+lOV1W3qarixy673g691wCTcC2eZbgrE7ZW9wOqmqOqORkZGT0Rbse8Czo1tjgmD08hTLBxDmNMvxKMxLG9sQvKuy3wyrcAw5odl+WVNTcRQFXXeUlnFnBUQKP1R3KWW8uxfQUAiTGRjBucZOMcxph+JRiJYza7Fw/OAF5uVn6ZN7vqCKCkWZdWoy3AgSLS2IQ4Gfgq0AF3WngkZB8Da99pKjo0O5XFm3bhq28IYmDGGNNzApo4ROQZ4BNgrIjkiciVwO3AySKyBjjJewwwB1gPrAUeBK5tVs8SAFXdCvwOd02QZbgWyB8DeQ5+G30y7PgaduUCbpyjsraer7aVBTcuY4zpIV0d4O4UVZ3exlMntnKsAj9so56Jze7fD9zfE/EFxOhT4I2bYM3bcNj3m13YaSfjs5I7eLExxuz7gjo43i8NGAWpI1ziAIYkx5KZEssiW0FujOknLHEEwuiTYcN8qHP7VB2ancqC3J24RpUxxvRtljgCYfQp4KuCjR8CbpyjoKyGzTttJ3pjTN9niSMQso+BiBhY42ZXHepteGjrOYwx/YEljkCIjIXsY2GtG+cYPTCBpJgIFm60xGGM6fsscQTK6JOhaC3sXE9YmHBodhofrt1h4xzGmD7PEkeg7H+Su/W6q049eDCbd1axeJPNrjLG9G2WOAJlwChIGwVr3gLgtPFDiIkM43+LW+6iYowxfYsljkAafTLkfgB1VSRER/DNgwbz6rJt1Pjqgx2ZMcZ0mSWOQBp9MviqIddNyz1nUiYlVXW8t6qXtnk3xpgAsMQRSPsdAxGxTavIj9k/nfSEaF78Ii/IgRljTNdZ4gikyBgY8Y2mcY6I8DDOmjiUd1cVUFxZG+TgjDGmayxxBNrok2HXBihaB7juqrp65dVlLXeMN8aYvsESR6A1Tct13VUHDU1izKAEXvzCZlcZY/omSxyBljYCBoxu6q4SEc6ZlMWijbvYWFQR5OCMMcZ/ljh6w+hT3Myq2koAzp40FBGs1WGM6ZMscfSG0SdBfY1b04G7RseRIwfw4hdbbAsSY0yfY4mjN+x3NETGNY1zgBsk31hUyeJNxcGLyxhjusASR2+IiIYRx8HXb4LXwmjcgsTWdBhj+hpLHL1l7KlQsgkKVgKQEB3BKQe6LUhqfQ1BDs4YYzrPEkdvGXOqu109p6nonMmZFFfW8d7qgiAFZYwx/rPE0VsSB0PmFFj9elPRsY1bkNiOucaYPsQSR28aexpsWQRl24E9tyDZUV4T5OCMMaZzLHH0prHT3O3XbzQVXXz4cBpUufPN1UEKyhhj/GOJozcNPBBShu/RXTUqI4HvHp3Ncws3s2RzcfBiM8aYTrLE0ZtEXKtj/XtNq8gBrjtxNBkJ0fz25eU0NNiCQGPMvi1giUNEHhGRAhFZ3qwsTUTeFpE13m2qVy4ico+IrBWRZSIyuY06o0TkARH5WkRWich5gYo/YMae5i7utH5eU1FiTCQ3TzuAZXklzFq4OXixGWNMJwSyxfEYcGqLspuAuao6GpjrPQY4DRjt/VwF/KuNOv8PKFDVMcCBwPs9HHPg7Xc0RCfvMS0X4KyJQzksO40/v7HKrtVhjNmnBSxxqOp8YGeL4rOAx737jwNnNyt/Qp1PgRQRGdJKtVcAf/Lqb1DVHT0eeKCFR7q9q75+Axp2L/wTEX531kGUVNXx17e+DmKAxhjTvt4e4xikqo1XMMoHBnn3M4HmfTR5XlkTEUnx7t4qIotF5L8iMoi+aMxpUFHopuY2c8CQJC47MpunPtvI8i0lQQrOGGPaF7TBcXXbwvozEhwBZAEfq+pk4BPgzrYOFpGrRGShiCwsLCzsXrA9bfRJIOF7dVcBXH/yGFLjomyg3Bizz+rtxLG9sQvKu23ca2MLMKzZcVleWXNFQCXwP+/xf4FWB9EBVPUBVc1R1ZyMjIyeiL3nxKbCfkftMS23UXJsJDeeNo7Fm4rteh3GmH1SbyeO2cAM7/4M4OVm5Zd5s6uOAEqadWkBTS2UV4CpXtGJwMqARxwoY6dB4Vewc/1eT50/OYtJw1P40+urKK2uC0JwxhjTtkBOx30G1500VkTyRORK4HbgZBFZA5zkPQaYA6wH1gIPAtc2q2dJs2pvBG4RkWXAd4CfByr+gBvbuOnhG3s9FRYm/P7MgymqqOGmF5ZRb11Wxph9iITCFehycnJ04cKFwQ5jb/88AuLT4fJXW336oQ/W84fXvuLSI4Zz61kHIyK9HKAxJpSJyCJVzWlZbivHg2nsabDxY6ja1erT3zt2JFcfN4r/fLqJu+eu6eXgjDGmdZY4gmnsNNB6WDu3zUNuPHUsF0zJ4q531vDkJ7m9F5sxxrTBEkcwZU6B+IxWp+U2EhH+dO54TjpgIL+dvYJXl23txQCNMWZvljiCKSzMXRlwzdtQUdTmYRHhYdw7fTI5+6Vy/XNL+HBN31swb4zpPyxxBNuE6VBbDncfAu/eBlXFrR4WGxXOQ5cdysj0BH7w5EKW5bV+nDHGBJoljmDLPhqu/RT2Pwnm/wXungAf/BVqyvc6NDkukieuPIyUuCgu/Pcn3Dt3DdV19UEI2hgTyixx7AsyxsKFj8MPPoDhR8Dc37sE8sk/oa5qj0MHJcXwwjVHccK4gfz17a859a75vLe6oI2KjTGm59k6jn3R5gXw7q2w4X2IHwhHXgs5V0JM0h6HfbCmkJmzV7C+sIKTDxzEb884kGFpcUEK2hjT37S1jsMSx74s90PXbbXuXYhJhsOugsOvgfgBTYfU+hp4+MMN3DN3DQ2qXDt1f2YctR8pcVFBDNwY0x9Y4uiLiaPRlsXw4d/gq1chMhamXA5H/RiShjYdsrW4itte+4rXvtxGVEQYp48fwsWHDydnv9T2V5y/fwfkL4ULHoew8MCfizGmz7DE0ZcTR6PC1fDhXbDsOYhLg+/NhdT99jjkq22lPPP5Jl5cvIWyGh+jByYw/bDhnDs5c+9WSN4ieOhEQOHU2+GIa3rtVIwx+z5LHP0hcTTavhIePRUSh8AVb0Jsyl6HVNb6eHXpNp7+fBNLNhcTFRHGpYfvx09OGk1ybCTU++DB46G8AAaOc+Mq136yVyLyy/t3QO58uPR/7kqHxpg+zfaq6k8GHQjffgqK1sGsy8C39zXK46IiuPDQYbz0w6OZc92xnD1xKI9+vIET/zqPWQs20/DZvyF/GZx2O5z5D/eiV6+Hrn6RKN0G8++ADfPhs/u7cXLG9JIGm8reVZY4+qoRx8KZ97qZV6+1/4F/4NAk/nL+BF750THsNyCev73wHjVv30pp1lQ48GxIGQYnzYR1c+HL/3Ytno/uhgYfZB0G826HUtsaxezDlj4HfxkBuR8FO5I+yRJHXzZxOhx3I3zxHzf7qgMHZybz/NVH8r8RLyNaz7R1Z/PL55dRUFoNh34Psg6F12+ECj+3NCnbDosehQkXwbkPQH0dvPXrLp6U6VdKt8LK2Z1vyarC5w/CslmBi6mhHt7/M1SXwDMXwbalgXuvQFGFHWth0WPwwvfdrhO92IKK6LV3MoEx9VfuKoLv3gqp2TD+/HYPl6/fYOi2d6iZ+htOrzqCRz7cwAuL85gwLIVzMn/OpVu/A2/8irDzHux8DB/fA/W1cOzPIW0EHPszmPcnmDwDRh7XvfMzva+qGIo3wZBDulfP12/Biz+Aqp1uHdK0O93+bG1RhXdugY/uAgmD5Cx3ieWetnoO7FwH3/wjfHIfPHmuGytM37/n36sn7dzgegVyP4KNH0H5dlcem+Z+x6VbXC9EL8yOtBZHXycCZ/0Thh8JL10Lmz5t+9jaCpjzS8g4gOhjf8KvTjuAt64/jh+fMBpVmPlpA/fWfouwL2fxzwfv578LN1PW0aVrywth4SMw/kIYMMqVHf0Tl8Tm/LLV8RcTACVbYP287tWhCkufhXunwL+/AV+/2bV66n3w9kx4+gJIynRJY+HDLonUt/H3pApv3uySxuQZ7u/n+Svb3fyzyz6+F1L2g8OvhstecmVPng0leT3/Xj1l8ZPwjxx47efu//iIb8AZd8GPFsIN690XyCVPwewf907LQ1X7/c+UKVO036soUr17kuqfhqu+83vVbctUGxr2PObNX6vOTFLd+EmrVewsr9FXF23Q/NsO1i0zR+kBNz6v4379uv7suSX62foibWhZn6rqW79RvSVFtfDrPctXv+He68O7eugEu2HbMtVl/w12FIGz7j3V27Pd7ztvYdfqKFit+ujpro4HTlC972jVPw5T3bHWv3pKtqg+/E1Xz+zrVGsr3d/h/Dtd2dMXqdZW7fma+nrVV3/mnp9zozt+yxeqv09X/c8Fe/8dd8fGT937fPrv3WVbvlD9Y5bqvTmq5Tt67r16Qn296tu3uJifONv9e7T1+3jvT+64F691r+sBwEJt5TPVWhz9RVwaXPJfGDrRLRa8/xj3DeXdP0D+cvfzyT9h8mVuP6xWpMZHcfrkbAZd+iBDKWTe5A84e1Imb67I58J/f8KJf32f+99fR2FZjXtBRRF8/hAcfB6kj96zsjHfdBeqmvdn9204WLavgMdOhxeudF0n/Ymq+/b85DmQMBDi0uGt3/g3M66uCubeCv86ys2yO+PvcOXbcNFTrsvj2Yuhpqxzda15x/3dbVsG5z4E37rbLVgVcd2Y0+503URPnb+7zoYGePUnsOAh11I99U/u+KET4ZTbYM2b7u+2p3xyL8SkwKRLdpcNnQjTn3Xdc0+dB9WlPfNe9T744inY0cWrd9ZVwfPfdf+fp3wXLp7lWvVtLeidehMcdxMs+Y/X8mjoeuwdsHUc/VF5Iax6BVa86LYt0QaIiIGoBPjRApdkOvLaz2HBw3DaX6ic+F1e+zKfWQs3syB3FxFhwjfGZHBD5CzGrnkQufZTtxakpV258M/DXQK54NEeP80O7doIj3zT3Y9OcoOh137SufPf19VWuA+H5S/AAWfC2fe5bqY5v4CLnoFx0zquY/37ro7ijXDIRXDKHyAho9nz81xSGncGXPhE2x9Yvho3pvXh32HgQW7DzpZfJBotfQ5eusZ9WF88yyW6pU/DN26A42/e8z1U4blL4es34Iq3IGtKZ387rSta57rhjv05nPibvZ//+k2XKIcf6b6ERcZ2/b2KN8ML34PNn0JYhFtc+40b9tpvrk3lhfDsdMhbCKfcCkf+qO3ff0vv/Qnevx0mXuqNeXS9fdDWOo6gdyP1xk9IdFW1paxA9fOHXJN/1ZzOv666zL1mZpLqf69wj1V1bUGZ/mnOV/rNP76kpb8dpK/95hS96okFOnvJFq2oqdu7nnl/dnWse69nzqezygq8rrthqvkrVLcuUf1dmup/v9u7cQRC0XrV+45SnZnsuoAauy58tar3THZdLr5W/i2ay1+heusgd/z699s+7qN73L/f/Dtbf37rUi+WJNWXf6RaU9Fx/F+96rqhbhvqXjfvz20fW7lT9W8Hq/79YNXKXR3X3Z5Xf+betzS/7WOWznK/13sPVd30edfeZ+Vs12V8W6bqwsdUX/qhq/OO0apfPN1xN1LBKtW/j3f/Pitndy2Gd2/rkW4r2uiqshaHaVtDg2smv3cbpI+BC5+EjDEA6Lt/QObfwX0HPslja+IoKKshNjKcI0cNYFRGPCPSE8hOj2NkSgSD/jMVCY+Ey+fs+Y02UGrK4LEzoHAVXPby7q65+Xe4rrvzH3Hda33RmrfdN1kUznsERp+05/NfvQrPXQKn/w0OvbL1Omor4IHjoWoXXPOR6+Zqi6p7v+UvwCXP736/ep9rYbx/O8QNgG/dA2NP7fx5rH8f/neV2/n56J+0f+zmBW6nhLHT2m/5tKeiCP5+kJt1eNY/2j927Tsw+ydultIR18IJv4aoTuw6XVftpqEveBCGTnJ/Z2kj3XNbFsGcG2DLQrfW6bQ/Q+ZkN1lgVy7s+NptKbRjDax6DSKi4eJn3eWlu0LVtQLn3wlXvgVZezcaOsO2HLHE0XXr3nNjBL4a959u5PFw13gYORW+/ST1DcqC3J28snQrC3N3kVtUQY1vd//qyVFfcn/Yn2mQcL5Mn8amsVeQMuxAhqfFkZkaS3REi+mD9XWw+TM3xXfk8f59UPhq4KkLXBfdRU/v+WFW73NdVzvXuYtnJQ72/3dRvBkqCt0HQ1c+wLpq10b3ofTVbBh4oBuDaPxQak4VHp0GRWvgui8gOnHvY168BpY+42YUjZza8XvXVsLDp0DJJrhqnvv3efFq2LoYDj4fpt3Rte4/1c7/Dj+6B97+DZx0Cww7wv0bVBS4NUcVhW5cYvJ33Gyj1rz/F/cF6NrPWu9WbammzE0NXvCQm+F15r1t1w1Q+LUbj9i+3HUrnTgTIlrsDdfQAMuedTPOKgrdv1/xJmhoNtMscQgMmeB+pynDO46zPapQ8JXbaaKLLHFY4uieki3w38sh73MYNB62fwlXfwiDx+91aEODsq20mg2FFWwoqmBDYQVV277i6MLnOLn2XSLx8U7DZP7tO4PFjGFCVioXjI1iWuxyUre85xJVjTdAOfgQ941v9Ckdf8g01LsEt+JFOPtfMPHivY/ZsQbuP9atvL94Vuc+uHy1blB38RNui3sUhh3uBiP9TWz+qq10q/I/ugvwBpmP+lH7/e95i+ChE1yf+gn/t+dzS552YwzH3ejGFDprVy48MBWiEt36gah4OONvcNA5/p9TVzQ0wDPfhjWtTHCITQXEtaCOud6dV/O90uqqXWsjcwpc4ufCwtwP3TjQzvVugDrnCre/W2me+z9RusVN481b4P5Nzr4fxpzSfp3VJa61tmONGwtKH+ta9OmjOz8G0ksscVji6D5frfvW99n9MPZ0mP6031U0lG6n6qP7iV7yCBE1xWxLOIiyqlrG1LuZJzvD0igcfBwZU75FWnit6wrZletWtZ/waxhx3N4f1BU7XAtl2SxY+RKc/Pv2uz8+vR/euNF1r0yZ0fZxhatdslj6DFQWQVIWTLrUdc18dLf78Mg6zCWQUSe0nkDKC9y30JIt3rfkHVC5Y/d9VfeNcPAhLgkPHu++vavCypddK6NkMxx0rhskTc7q3C/6v991g8o/XgxJQ1xZwSq3sWXmFNeF5+9CsXXvutbcmFPd7Kv2urgCobbCdSNFJbj3js9w/xbhke65N25y/16ZOXDeQ24xKrjV1a/8BGa86r4w+P2+la618ul9bqJJIwmDhMGQnOk+/E/4vz0uddAfWOKwxNFzNi9wq2xjU7teR22F+/a74GGITmBX5vG8VTeBx9cnsTLfTdWcsl8qpx0wgHPkfQYsust9u8s+1l2LpCzfJYvNn0HRWldneJRLGCd0sN1JQwM8cSZs/cL18admu/LqUre4auOHrg9+2xI3I2bsNLcobdTxuz9sfTVuwdX8v3oJ5FAXV12VSxT5y91tReGe7x0ZD/Hp7icu3X0QbV8OZdt2H5M8zE0Z3f4lDDrY9YdnH+Pf73fnBvjHoW4bmLP+4T78HjzBxXP1h7uTib9qyl1roze76fyx4kU3PqENrkV08Pnwz8NczFfN617c+cvduFlyllvYmDi43+8CbYnDEkefsb6wnNeWbeP15fms3Oa6rCYMjuH6tI85Jv8JIiq9a6zHDXD93cMOcwPgQyZCZEzn3qR4E9x3FAw8wL0290OXKLQBwiLdYOLY02DCxe0P6PtqXQL54K+uZQAQHu360QeNh8EHw6CDXHKKS297kLW80K2jyP/S3e7KdV1tky+H8C7uDPTGzfDZv+Dqj+DTf7o1BZe+APuf2LX6+oriTW7/ps2fuqm1mz6B8x7ucDses7egJA4ReQQ4AyhQ1YO9sjTgOSAbyAUuVNVd4i5TdzcwDagELlfVxe3UPRsY2Vhveyxx9F2biip5a2U+byzPZ9GmXURrDeekrGPsQRM54cijGJ4e3/XKv3gKXr7WtVQyc9y3+uyjXfdTZ2bRNOerdS2VxCEwYHTXP+x7UuVOuGeiu+xw8SZv/cJvgx1V76j3uVl08//iWgfXLdk3/k36mGAljm8A5cATzRLHX4Cdqnq7iNwEpKrqjSIyDfgxLnEcDtytqoe3Ue+5wPnAIZY4QkdBWTVvr9zOa8u28cn6IlTh0OxUzp2cxbTxQ9wFqvxVuNp1DfmbKPqKxtlIw4+CGa+E3ofntmVu8as3jdz4J2hdVSKSDbzaLHGsBqaq6jYRGQLMU9WxIvJv7/4zLY9rUV8C8AZwFTDLEkdo2lpcxUtLtvDCojzWFVYQFRHGyQcO4uhR6WQPiCM7PZ7BSTGEhe2jffG9xVfjxpEOPg8SBwU7GtPHtJU4gvH1Y1CzZJAPNP41ZwKbmx2X55XtkTiAW4G/4rqz2iQiV+GSC8OHd3M+tNnnDE2J5dqp+3PNcaP4cksJ/1u8hdlLt/Last1/LtERYew3II79BsQzMiOeAwYnMXZwIqMyEoiKCJFt2iKi3SI7Y3pQUNutqqoi0ukmj4hMBEap6vVeS6a9uh8AHgDX4uhOnGbfJSIckpXCIVkp/PaMA9lWWs3GHW79yMaiSjbsqGBjUQXvry6ktt5NpYwIE/YfmMC4wYmMHZzE6IEJjBqYwLDUWCLCQyShGNMNwUgc20VkSLOuKm+KDFuAYc2Oy/LKmjsSyBGRXFzsA0VknqpODXDMpg8ICxMyU2LJTInlqP3T93iurr6BDTsq+GpbKavyy1i1rZTPN+zkpSW7L3EbFR5GdnocozISGJWRQGp8FBFhQniYEBkuhIeFEREmpMZHMXl4Cokx/XsqpjFtCUbimA3MAG73bl9uVv4jEXkWNzhe0nJ8Q1X/BfwL9hg7mdo7YZu+LDI8jDGDEhkzKJGzmpWXVNaxbkc56wrKWVdYwdqCclbnl/HWyu3UN7TdUA0Tdynew0ekccTIAeRkp3VtcN6YPiigiUNEngGmAukikgfMxCWMWSJyJbARuNA7fA5uRtVa3PjFd5vVs0RVJwYyVhOakuMimTw8lcnD91zMWFffQGVtPb76BuobFF+D4qtXfA0N5JdU8+mGnXy6vojHP97Igx9sQATGDU4iMyWWAfFRpCVEudv4KAYkRDM8LY790uJssN70C7YA0JhuqK6r54tNxXy6vojFm3ZRWFZDUUUtuypq8bVoscRGhjN2cCIHDElk3OAkDhjixldS4iKRfXUltglptnLcEofpRapKaZWPogqXSDYUVvBVfimrtpXxVX4pxZW7d0SNjwonM9WNzWSluh2Dh3otl5S4SFLjXMslJtLPvaWM6aZ9aTquMf2eiJAcF0lyXCQjM+DQ7N3bjqsqBWU1fLWtlLUF5WwprmLLrirydlWxeFMxJVV1rdYZExlGalwUcVHhRIaHERURRmR4GJHhQlREOLGRYWQkRjMwMca73X0/NT5y7+3rjekiSxzG9DIRYVBSDIOSYpg6du8dZstrfGwtrmJnRS3FlbXsqqzb435VXT11vgbq6huoq1dq6xsoq64jv8TH5xt2squy9cQTFxVOSmwkKXFRpMa72yFJMYzIiGdkegIjM+IZmBht3WamQ5Y4jNnHJERHMGZQKxdg6qRaXwM7ymsoKKuhoLSawvIaiivr2FXhEo9LQLVsKy7lnZXb97joVnxUOCMy4hmeFkdybBTJsZF7/KTEudu0+ChS46KIjbJWTCiyxGFMPxMVEcbQFDdO0pHmF91av6Oc9YUVbNhRwer8MkqqfJRU1VJX3/Y4aHSE6z5LjY8iITqc6IhwoiPCiI4MIyo8zD2ODCMmMpyYiDCiI8Pd/cgwYiLCiY+OICkmgoSYCBKiI0iMiSQxJoLoiDBr+ezDLHEYE8KaL5o8ZnT6Xs+rKlV19ZRU1bmfyrpmrZY6dlXWNrVkKmt9VNXVU1xVS01dAzW+Bmp89dT4Gqiuq6e6rqGVCFoXHibERYYTGxVOXFQ4sVERxEe5xwnREcRFRZAQHU5ctEs48VHhXhdcFGleV1xafBSxkeGWgALAEocxpk0iQlyU+6AektxxC6Y9quqSSV0D1b56qmrrqaj1UVbto7zaR3mNj7IaH2XVdVTWuOeqauuprK2nstZHZW09pdU+8kuqqaytp7zGR0WNb69pz81FR4SRFBvpkkt0OPFRLtEkxEQQHx1BYkwEiV5LJ8F7nBDtPhZrvTEkN5bUQK2vAREhNjKc2CjXioptTG6Rrs7EmAgiQ2DbGkscxpheISJeN1U4yfTcKvsaXz0VNfVNYzc7K9x4zk6vNVRaXUd5TT3l1XVU1NSzraSaikKXrMpqfNT6Ot8S6oyYyLCmLrfEmEhiI8OadeE1dtmFERUeTmSEEB3uzY6LcN17URFhLrlF705u8d7juCj3+wsP8kJSSxzGmD7NfSiHkxYf1aXX1/jqd7d4qt1PmND0Qd445TkyPAxVqKqrdz+19VR79ytqmr++rqmeshof1XUuqbmuuwZq6uqb7td6LRl/RYWHERMZRmyUa/WEhwmqUK9KgyoNDbhbVZ676kiyu3PBs1ZY4jDGhLToiHCiE8IZkBAdlPdXdVva1NU3UOdTqn27E1F5ze5uvPIan5esGqiqq/fGjVzi8tUrYWFCmEC4CCLe/TAhLgAz3yxxGGNMEIlIU4uGKHq0Gy9Q+v8ojjHGmB5licMYY4xfLHEYY4zxiyUOY4wxfrHEYYwxxi+WOIwxxvjFEocxxhi/WOIwxhjjl5C4dKyIFAIbgXRgR5DDCaZQPv9QPncI7fO3c++6/VQ1o2VhSCSORiKysLXr54aKUD7/UD53CO3zt3Pv+XO3ripjjDF+scRhjDHGL6GWOB4IdgBBFsrnH8rnDqF9/nbuPSykxjiMMcZ0X6i1OIwxxnSTJQ5jjDF+CZnEISKnishqEVkrIjcFO55AE5FHRKRARJY3K0sTkbdFZI13mxrMGANFRIaJyHsislJEVojIT7zyfn/+IhIjIp+LyFLv3H/nlY8Qkc+8v//nRKRr11ntA0QkXES+EJFXvcehdO65IvKliCwRkYVeWY//3YdE4hCRcOCfwGnAgcB0ETkwuFEF3GPAqS3KbgLmqupoYK73uD/yAT9X1QOBI4Afev/eoXD+NcAJqjoBmAicKiJHAH8G/q6q+wO7gCuDF2LA/QT4qtnjUDp3gONVdWKz9Rs9/ncfEokDOAxYq6rrVbUWeBY4K8gxBZSqzgd2tig+C3jcu/84cHZvxtRbVHWbqi727pfhPkQyCYHzV6fcexjp/ShwAvC8V94vzx1ARLKA04GHvMdCiJx7O3r87z5UEkcmsLnZ4zyvLNQMUtVt3v18YFAwg+kNIpINTAI+I0TO3+uqWQIUAG8D64BiVfV5h/Tnv/+7gBuABu/xAELn3MF9SXhLRBaJyFVeWY//3Ud0twLTN6mqiki/nostIgnAC8BPVbXUffl0+vP5q2o9MFFEUoAXgXHBjah3iMgZQIGqLhKRqUEOJ1iOUdUtIjIQeFtEVjV/sqf+7kOlxbEFGNbscZZXFmq2i8gQAO+2IMjxBIyIROKSxlOq+j+vOGTOH0BVi4H3gCOBFBFp/KLYX//+jwbOFJFcXHf0CcDdhMa5A6CqW7zbAtyXhsMIwN99qCSOBcBob3ZFFHARMDvIMQXDbGCGd38G8HIQYwkYr1/7YeArVf1bs6f6/fmLSIbX0kBEYoGTcWM87wHne4f1y3NX1V+papaqZuP+j7+rqpcQAucOICLxIpLYeB84BVhOAP7uQ2bluIhMw/V/hgOPqOptwY0osETkGWAqblvl7cBM4CVgFjAct838haracgC9zxORY4APgC/Z3dd9M26co1+fv4gcghsADcd9MZylqr8XkZG4b+FpwBfApapaE7xIA8vrqvqFqp4RKufuneeL3sMI4GlVvU1EBtDDf/chkziMMcb0jFDpqjLGGNNDLHEYY4zxiyUOY4wxfrHEYYwxxi+WOIwxxvjFEocxXSQi9d4upI0/PbZpoohkN9/Z2Jh9iW05YkzXVanqxGAHYUxvsxaHMT3MuybCX7zrInwuIvt75dki8q6ILBORuSIy3CsfJCIvetfQWCoiR3lVhYvIg951Nd7yVoIjItd51xpZJiLPBuk0TQizxGFM18W26Kr6drPnSlR1PPAP3I4FAPcCj6vqIcBTwD1e+T3A+941NCYDK7zy0cA/VfUgoBg4zyu/CZjk1XN1YE7NmLbZynFjukhEylU1oZXyXNzFlNZ7my3mq+oAEdkBDFHVOq98m6qmi0ghkNV8GwxvO/i3vYvvICI3ApGq+gcReQMox20h81Kz628Y0yusxWFMYGgb9/3RfD+lenaPSZ6Ou6LlZGBBs51fjekVljiMCYxvN7v9xLv/MW7XVoBLcBsxgruc5zXQdBGm5LYqFZEwYJiqvgfcCCQDe7V6jAkk+6ZiTNfFelfaa/SGqjZOyU0VkWW4VsN0r+zHwKMi8kugEPiuV/4T4AERuRLXsrgG2EbrwoH/eMlFgHu8624Y02tsjMOYHuaNceSo6o5gx2JMIFhXlTHGGL9Yi8MYY4xfrMVhjDHGL5Y4jDHG+MUShzHGGL9Y4jDGGOMXSxzGGGP88v8AIR5y8q6piQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4976832) must match the size of tensor b (119443968) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluating\"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m precisions, recalls, F1s, IOUs \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m mean_precision \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(precisions)\n\u001b[1;32m    159\u001b[0m mean_recall \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(recalls)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(eval_model, testing_loader)\u001b[0m\n\u001b[1;32m     84\u001b[0m prediction \u001b[38;5;241m=\u001b[39m predict_img(eval_model, transform(image), DEVICE, untransform, out_threshold\u001b[38;5;241m=\u001b[39mcst\u001b[38;5;241m.\u001b[39mTHRESHOLD)\n\u001b[1;32m     85\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(prediction)\n\u001b[0;32m---> 87\u001b[0m precisions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     88\u001b[0m recalls\u001b[38;5;241m.\u001b[39mappend(metrics\u001b[38;5;241m.\u001b[39mrecall(pred, mask))\n\u001b[1;32m     89\u001b[0m F1s\u001b[38;5;241m.\u001b[39mappend(metrics\u001b[38;5;241m.\u001b[39mF1Score(pred, mask))\n",
      "File \u001b[0;32m/notebooks/metrics.py:34\u001b[0m, in \u001b[0;36mprecision\u001b[0;34m(prediction, groundtruth)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(prediction, groundtruth):\n\u001b[0;32m---> 34\u001b[0m     tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroundtruth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tp \u001b[38;5;241m/\u001b[39m (tp \u001b[38;5;241m+\u001b[39m fp \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.00000001\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/metrics.py:17\u001b[0m, in \u001b[0;36mconfusion\u001b[0;34m(prediction, truth)\u001b[0m\n\u001b[1;32m     14\u001b[0m prediction \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m truth \u001b[38;5;241m=\u001b[39m truth\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m confusion_vector \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruth\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Element-wise division of the 2 tensors returns a new tensor which holds a\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# unique value for each case:\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#   1     where prediction and truth are 1 (True Positive)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#   inf   where prediction is 1 and truth is 0 (False Positive)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#   nan   where prediction and truth are 0 (True Negative)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#   0     where prediction is 0 and truth is 1 (False Negative)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m true_positives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(confusion_vector \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4976832) must match the size of tensor b (119443968) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "for TERM in TERMS:\n",
    "    print(\"Starting term: \" + TERM)\n",
    "    start_term = time.time()\n",
    "    \n",
    "    image_folder = \"/notebooks/images\"\n",
    "    mask_folder = \"/notebooks/\" + TERM\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                    transforms.Pad((0, 64, 0, 64))])\n",
    "    untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                     transforms.Resize((1932, 2576))])\n",
    "    \n",
    "    fold_validation = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    fold_IOU = []\n",
    "    \n",
    "    for fold in FOLDS:\n",
    "        print(\"Starting fold: {}\".format(fold))\n",
    "        start_fold = time.time()\n",
    "        \"\"\"Datasets and loaders\"\"\"\n",
    "        training_set = dataset.ZebrafishDataset(image_folder,\n",
    "                                                      mask_folder,\n",
    "                                                      actual_fold=fold,\n",
    "                                                      dataset=\"train\",\n",
    "                                                      folds=cst.FOLDS)\n",
    "        validation_set = dataset.ZebrafishDataset(image_folder,\n",
    "                                                        mask_folder,\n",
    "                                                        actual_fold=fold,\n",
    "                                                        dataset=\"validate\",\n",
    "                                                        folds=cst.FOLDS)\n",
    "        testing_set = dataset.ZebrafishDataset(image_folder,\n",
    "                                                     mask_folder,\n",
    "                                                     actual_fold=fold,\n",
    "                                                     dataset=\"test\",\n",
    "                                                     folds=cst.FOLDS)\n",
    "\n",
    "        training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                                      batch_size=cst.BATCH_SIZE,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=cst.WORKERS)\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                        batch_size=cst.BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=cst.WORKERS)\n",
    "\n",
    "        testing_loader = torch.utils.data.DataLoader(testing_set,\n",
    "                                                     batch_size=1,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=cst.WORKERS)\n",
    "        \n",
    "        model = UNET(3, 25)\n",
    "        model.to(DEVICE)\n",
    "        best_model = UNET(3, 25)\n",
    "        best_model = model\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion_string = \"CE\"\n",
    "\n",
    "        if cst.LOSS == \"Dice\":\n",
    "            print(\"Loss used: Dice\")\n",
    "            criterion = loss_fn.DiceLoss()\n",
    "            criterion_string = \"DCE\"\n",
    "        if cst.LOSS == \"IOU\":\n",
    "            print(\"Loss used: IOU\")\n",
    "            criterion = loss_fn.IoULoss()\n",
    "            criterion_string = \"IOU\"\n",
    "        if cst.LOSS == \"Loss used: Tversky\":\n",
    "            print(\"Loss used: Tversky\")\n",
    "            criterion = loss_fn.TverskyLoss(alpha=0.7, beta= 0.3)\n",
    "            criterion_string = \"Tversky\"\n",
    "        if cst.LOSS == \"Focal\":\n",
    "            print(\"Loss used: Focal\")\n",
    "            criterion = loss_fn.FocalLoss(alpha=0.8, gamma= 2, reduction=\"mean\")\n",
    "            criterion_string = \"Focal\"\n",
    "\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=cst.LEARNING_RATE, weight_decay=cst.WEIGHT_DECAY)\n",
    "        optimiser_string = \"ADAM\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        if cst.OPTIMIZER == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                        lr=cst.LEARNING_RATE,\n",
    "                                        momentum=cst.MOMENTUM,\n",
    "                                        weight_decay=cst.WEIGHT_DECAY)\n",
    "            optimiser_string = \"SGD\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"M\" + str(cst.MOMENTUM)\n",
    "            optimiser_string += \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        params_string = \"Params\" + \"_\" + \"Epoch\" + str(cst.EPOCHS) + \"_\" + \"BS\" + str(cst.BATCH_SIZE)\n",
    "        params_string += \"_\" + \"W\" + str(cst.WORKERS)\n",
    "        \n",
    "        \"\"\"Computing validation loss before training\"\"\"\n",
    "        loss = validate(model, validation_loader, transform, DEVICE)\n",
    "            \n",
    "        best_val = loss\n",
    "        best_epoch = 0\n",
    "        last_epoch = 0\n",
    "        \n",
    "        epochs_train_losses = []\n",
    "        epochs_val_losses = []\n",
    "        for epoch in range(cst.EPOCHS):\n",
    "            # Training\n",
    "            loss = train(model, training_loader, transforms, DEVICE, criterion, optimiser)\n",
    "            epochs_train_losses.append(loss)\n",
    "\n",
    "            \"\"\"Validation\"\"\"\n",
    "            loss = validate(model, validation_loader, transform, DEVICE)\n",
    "            epochs_val_losses.append(loss)\n",
    "\n",
    "            # Updating best model\n",
    "            if loss < best_val:\n",
    "                best_val = loss\n",
    "                best_model = model\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "            if (epoch+1)%1 == 0:\n",
    "                print(\"Epoch: \" + str(epoch+1))\n",
    "                print(\"Validation: {}.\".format(loss))\n",
    "                print(\"Best validation: {}.\".format(best_val))\n",
    "                    \n",
    "            \"\"\"Train and validate loops over\"\"\"\n",
    "            curr = time.time()\n",
    "            curr = curr - start_term\n",
    "            secondes = curr % 60\n",
    "            minutes = (curr-secondes)/60\n",
    "            \n",
    "            last_epoch = epoch\n",
    "            \n",
    "            # Notebooks shutdown after 6 hours. Stop the code and save the results.\n",
    "            if minutes >= 350:\n",
    "                break\n",
    "            if (epoch - best_epoch) >= 50:\n",
    "                break\n",
    "            \n",
    "        \"\"\"All epochs are over\"\"\"\n",
    "        fold_validation.append(best_val)\n",
    "        \n",
    "        model_name = TERM + '_' + cst.LOSS + \"_Fold_\" + str(fold) + \"_Epoch_\" + str(best_epoch) + \"_MaxEpochs_\" \n",
    "        model_name += str(cst.EPOCHS) + '_' + cst.OPTIMIZER + \"_LR_\" + str(cst.LEARNING_RATE) + \".pth\"\n",
    "        \n",
    "        model_filepath = os.path.join(cst.MODEL, model_name)\n",
    "        torch.save(best_model.state_dict(), model_filepath)\n",
    "        \n",
    "        # Plot losses\n",
    "        index = [i+1 for i in range(last_epoch+1)]\n",
    "        plt.plot(index[1:], epochs_train_losses[1:], label=\"Training\")\n",
    "        plt.plot(index[1:], epochs_val_losses[1:], label=\"Validation\")\n",
    "        plt.title(TERM + \" \" + str(cst.LOSS) + \" Fold \" + str(fold)) \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\"Evaluating\"\"\"\n",
    "        precisions, recalls, F1s, IOUs = evaluate(best_model, testing_loader)\n",
    "        \n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(F1s)\n",
    "        mean_IOU = np.mean(IOUs)\n",
    "        \n",
    "        fold_precision.append(mean_precision)\n",
    "        fold_recall.append(mean_recall)\n",
    "        fold_f1.append(mean_f1)\n",
    "        fold_IOU.append(mean_IOU)\n",
    "        \n",
    "        confidence = 0.9\n",
    "        \n",
    "        curr = time.time()\n",
    "        curr = curr - start_fold\n",
    "        secondes = curr % 60\n",
    "        minutes = (curr-secondes)/60\n",
    "        #print(\"--------------------\")\n",
    "        print(\"Last epoch: {}\".format(last_epoch))\n",
    "        print(\"Term: \" + TERM)\n",
    "        print(\"Fold: {}\".format(fold))\n",
    "        print(\"Fold took: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds to train\")\n",
    "        print(\"Last val: {}\".format(loss))\n",
    "        print(\"Best val: {}\".format(best_val))\n",
    "        print()\n",
    "        print(\"Precision: {}\".format(mean_precision))\n",
    "        print(\"90% CI: {}\".format(np.percentile(precisions, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(precisions), np.max(precisions))\n",
    "        print()\n",
    "\n",
    "        print(\"Recall: {}\".format(mean_recall))\n",
    "        print(\"90% CI: {}\".format(np.percentile(recalls, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(recalls), np.max(recalls))\n",
    "        print()\n",
    "\n",
    "        print(\"F1/Dice score: {}\".format(mean_f1))\n",
    "        print(\"90% CI: {}\".format(np.percentile(F1s, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(F1s), np.max(F1s))\n",
    "        print()\n",
    "\n",
    "        print(\"IoU: {}\".format(mean_IOU))\n",
    "        print(\"90% CI: {}\".format(np.percentile(IOUs, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(IOUs), np.max(IOUs))\n",
    "        print()\n",
    "        print(\"--------------------\")\n",
    "    \"\"\"Fold loop end\"\"\"\n",
    "    print()\n",
    "    print(\"ALL FOLDS TRAINING ENDED\")\n",
    "    print(\"Mean best validation: {}\".format(np.mean(fold_validation)))\n",
    "    print(\"Mean precision: {}\".format(np.mean(fold_precision)))\n",
    "    print(\"Mean recall: {}\".format(np.mean(fold_recall)))\n",
    "    print(\"Mean F1: {}\".format(np.mean(fold_f1)))\n",
    "    print(\"Mean IOU: {}\".format(np.mean(fold_IOU)))\n",
    "\"\"\"term loop end\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4371d80-227c-43f3-8a78-0a55c1a9861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a a a a a a a a a a a a a a a a a a a \n",
      "torch.Size([1, 25, 512, 512])\n",
      "torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "for image, mask, name in testing_loader:\n",
    "    print(\"a\",end=\" \")\n",
    "image = transform(image)\n",
    "output = best_model(image.to(DEVICE))\n",
    "print()\n",
    "predictions = torch.nn.functional.softmax(output, dim=1)\n",
    "print(predictions.shape)\n",
    "pred_labels = torch.argmax(predictions, dim=1)\n",
    "print(pred_labels.shape)\n",
    "plt.imshow(pred_labels.cpu().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51453afd-4b78-49ea-a55c-4542025bc00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
