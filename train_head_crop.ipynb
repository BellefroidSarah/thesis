{
 "cells": [
  {
   "cell_type": "raw",
   "id": "30729826-0e1f-4538-890c-826332a10138",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on October 29, 2022\n",
    "\n",
    "The following things are implemented:\n",
    "    - Kfold cross validation avg\n",
    "    \n",
    "To implement:\n",
    "    - Stop training when no improvement\n",
    "    - Use network to crop the fish out (will need to change dataset.py, transform fct will be different for every img)\n",
    "    \n",
    "Things to think about:\n",
    "    - Decrease LR \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db6b7f3-c1ef-44f5-9e24-1a3ab9a6625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import dataset\n",
    "import metrics\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import loss_fn_v2 as loss_fn\n",
    "import torchvision.transforms.functional as FF\n",
    "\n",
    "from unet import UNET\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981836a3-16e4-4e12-9ef3-b60da9526b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def validate(model, validation_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for images, masks, _, _ in validation_loader:\n",
    "            outputs = model(images.to(DEVICE))\n",
    "\n",
    "            masks = masks.type(torch.LongTensor)\n",
    "            masks = torch.squeeze(masks, 1)\n",
    "\n",
    "            vloss = criterion(outputs, masks.to(DEVICE))\n",
    "            loss = vloss.detach().item()\n",
    "            val_loss.append(loss)\n",
    "\n",
    "        loss = np.mean(val_loss)\n",
    "        # print(\"Validation loss before training: {}\".format(loss))\n",
    "    return loss\n",
    "\n",
    "def train(model, training_loader, criterion, optimiser):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for images, masks, _, _ in training_loader:\n",
    "        outputs = model(images.to(DEVICE))\n",
    "\n",
    "        masks = masks.type(torch.LongTensor)\n",
    "        masks = torch.squeeze(masks, 1)\n",
    "\n",
    "        tloss = criterion(outputs, masks.to(DEVICE))\n",
    "        loss = tloss.detach().item()\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        tloss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    loss = np.mean(train_loss)\n",
    "    return loss\n",
    "\n",
    "def evaluate(eval_model, testing_loader):\n",
    "    tps = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    IOUs = []\n",
    "    \n",
    "    eval_model.eval()\n",
    "    for image, mask, name, size in testing_loader:\n",
    "        h_length = int(size[0])\n",
    "        v_length = int(size[1])\n",
    "        if h_length>v_length:\n",
    "            untr = transforms.Compose([transforms.Resize((h_length, h_length)),\n",
    "                                       transforms.CenterCrop((v_length, h_length))])\n",
    "        elif h_length<v_length:\n",
    "            untr = transforms.Compose([transforms.Resize((v_length, v_length)),\n",
    "                                       transforms.CenterCrop((v_length, h_length))])\n",
    "        else:\n",
    "            untr = transforms.Compose([transforms.Resize((h_length, h_length))])\n",
    "\n",
    "        image_name = name[0]\n",
    "        \n",
    "        prediction = utils.predict_img(eval_model, image, DEVICE, untr, out_threshold=cst.THRESHOLD)\n",
    "        pred = torch.from_numpy(prediction)\n",
    "        \"\"\"pr = pred * 1\n",
    "        pr = pr.unsqueeze(dim=0)\n",
    "        show_images(pr)\n",
    "\n",
    "        mask = untr(mask)\"\"\"\n",
    "\n",
    "        precisions.append(metrics.precision(pred, mask))\n",
    "        recalls.append(metrics.recall(pred, mask))\n",
    "        F1s.append(metrics.F1Score(pred, mask))\n",
    "        IOUs.append(metrics.IOUScore(pred, mask))\n",
    "    return precisions, recalls, F1s, IOUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0dfda9-ebcf-4005-8b56-e4fa3e006535",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)\n",
    "\n",
    "# Model used to first crop the fish out of the image\n",
    "model_name = \"fish_CE_Fold_4_Epoch_95_MaxEpochs_600_Adam_LR_0.0001.pth\"\n",
    "model_path = os.path.join(cst.MODEL, model_name)\n",
    "\n",
    "fish_model = utils.load_model(model_path)\n",
    "fish_model.to(DEVICE)\n",
    "\n",
    "TERMS = [\"p\"]\n",
    "SIZE = (384, 512)\n",
    "FOLDS = [4]    # 0 to 4 only a few folds at a time here for computational resources limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3787354-d69c-4cde-96ef-19a253735f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting term: p\n",
      "Starting fold: 4\n",
      "Training set length: 84\n",
      "Validation set length: 20\n",
      "Testing set length: 20\n",
      "Loss used: Tversky\n"
     ]
    }
   ],
   "source": [
    "for TERM in TERMS:\n",
    "    print(\"Starting term: \" + TERM)\n",
    "    start_term = time.time()\n",
    "    \n",
    "    image_folder = \"/notebooks/images\"\n",
    "    mask_folder = \"/notebooks/\" + TERM\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                    transforms.Pad((0, 64, 0, 64))])\n",
    "    untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                     transforms.Resize((1932, 2576))])\n",
    "    \n",
    "    fold_validation = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    fold_IOU = []\n",
    "    \n",
    "    for fold in FOLDS:\n",
    "        print(\"Starting fold: {}\".format(fold))\n",
    "        start_fold = time.time()\n",
    "        \"\"\"Datasets and loaders\"\"\"\n",
    "        training_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"train\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "\n",
    "        validation_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"validate\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "        \n",
    "        testing_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"test\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "\n",
    "        training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                                      batch_size=cst.BATCH_SIZE,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=cst.WORKERS)\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                        batch_size=cst.BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=cst.WORKERS)\n",
    "\n",
    "        testing_loader = torch.utils.data.DataLoader(testing_set,\n",
    "                                                     batch_size=1,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=cst.WORKERS)\n",
    "        \n",
    "        \n",
    "        model = UNET(3, 2)\n",
    "        model.to(DEVICE)\n",
    "        best_model = UNET(3, 2)\n",
    "        best_model = model\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion_string = \"CE\"\n",
    "\n",
    "        if cst.LOSS == \"Dice\":\n",
    "            print(\"Loss used: Dice\")\n",
    "            criterion = loss_fn.DiceLoss()\n",
    "            criterion_string = \"DCE\"\n",
    "        if cst.LOSS == \"IOU\":\n",
    "            print(\"Loss used: IOU\")\n",
    "            criterion = loss_fn.IoULoss()\n",
    "            criterion_string = \"IOU\"\n",
    "        if cst.LOSS == \"Tversky\":\n",
    "            print(\"Loss used: Tversky\")\n",
    "            criterion = loss_fn.TverskyLoss(alpha=0.7, beta= 0.3)\n",
    "            criterion_string = \"Tversky\"\n",
    "        if cst.LOSS == \"Focal\":\n",
    "            print(\"Loss used: Focal\")\n",
    "            criterion = loss_fn.FocalLoss(alpha=0.8, gamma= 2, reduction=\"mean\")\n",
    "            criterion_string = \"Focal\"\n",
    "\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=cst.LEARNING_RATE, weight_decay=cst.WEIGHT_DECAY)\n",
    "        optimiser_string = \"ADAM\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        if cst.OPTIMIZER == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                        lr=cst.LEARNING_RATE,\n",
    "                                        momentum=cst.MOMENTUM,\n",
    "                                        weight_decay=cst.WEIGHT_DECAY)\n",
    "            optimiser_string = \"SGD\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"M\" + str(cst.MOMENTUM)\n",
    "            optimiser_string += \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        params_string = \"Params\" + \"_\" + \"Epoch\" + str(cst.EPOCHS) + \"_\" + \"BS\" + str(cst.BATCH_SIZE)\n",
    "        params_string += \"_\" + \"W\" + str(cst.WORKERS)\n",
    "        \n",
    "        \"\"\"Computing validation loss before training\"\"\"\n",
    "        loss = validate(model, validation_loader, criterion)\n",
    "            \n",
    "        best_val = loss\n",
    "        best_epoch = 0\n",
    "        last_epoch = 0\n",
    "        \n",
    "        epochs_train_losses = []\n",
    "        epochs_val_losses = []\n",
    "        for epoch in range(cst.EPOCHS):\n",
    "            \"\"\" Training \"\"\"\n",
    "            loss = train(model, training_loader, criterion, optimiser)\n",
    "            epochs_train_losses.append(loss)\n",
    "\n",
    "            \"\"\" Validation \"\"\"\n",
    "            loss = validate(model, validation_loader, criterion)\n",
    "            epochs_val_losses.append(loss)\n",
    "            \n",
    "            # Updating best model\n",
    "            if loss < best_val:\n",
    "                best_val = loss\n",
    "                best_model = model\n",
    "                best_epoch = epoch+1\n",
    "            \n",
    "            if (epoch+1)%50 == 0:\n",
    "                print(\"Epoch: \" + str(epoch+1))\n",
    "                print(\"Validation: {}.\".format(loss))\n",
    "                print(\"Best: {}.\".format(best_val))\n",
    "                    \n",
    "            \"\"\"Train and validate loops over\"\"\"\n",
    "            curr = time.time()\n",
    "            curr = curr - start_term\n",
    "            secondes = curr % 60\n",
    "            minutes = (curr-secondes)/60\n",
    "            \n",
    "            last_epoch = epoch\n",
    "            \n",
    "            # Notebooks shutdown after 6 hours. Stop the code and save the results.\n",
    "            if minutes >= 350:\n",
    "                break\n",
    "            if (epoch - best_epoch) >= 50:\n",
    "                break\n",
    "            \n",
    "        \"\"\"All epochs are over\"\"\" \n",
    "        fold_validation.append(best_val)\n",
    "        \n",
    "        model_name = TERM + '_head_crop_' + cst.LOSS + \"_Fold_\" + str(fold) + \"_Epoch_\" + str(best_epoch) + \"_MaxEpochs_\" \n",
    "        model_name += str(cst.EPOCHS) + '_' + cst.OPTIMIZER + \"_LR_\" + str(cst.LEARNING_RATE) + \".pth\"\n",
    "        \n",
    "        model_filepath = os.path.join(cst.MODEL, model_name)\n",
    "        torch.save(best_model.state_dict(), model_filepath)\n",
    "        \n",
    "        index = [i+1 for i in range(last_epoch+1)]\n",
    "        plt.plot(index[1:], epochs_train_losses[1:], label=\"Training\")\n",
    "        plt.plot(index[1:], epochs_val_losses[1:], label=\"Validation\")\n",
    "        plt.title(str(cst.LOSS) + \" Fold \" + str(fold)) \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\"Evaluating\"\"\"\n",
    "        precisions, recalls, F1s, IOUs = evaluate(best_model, testing_loader)\n",
    "        \n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(F1s)\n",
    "        mean_IOU = np.mean(IOUs)\n",
    "        \n",
    "        fold_precision.append(mean_precision)\n",
    "        fold_recall.append(mean_recall)\n",
    "        fold_f1.append(mean_f1)\n",
    "        fold_IOU.append(mean_IOU)\n",
    "        \n",
    "        confidence = 0.9\n",
    "        \n",
    "        curr = time.time()\n",
    "        curr = curr - start_fold\n",
    "        secondes = curr % 60\n",
    "        minutes = (curr-secondes)/60\n",
    "        \n",
    "        #print(\"--------------------\")\n",
    "        print(\"Last epoch: {}\".format(last_epoch))\n",
    "        print(\"Term: \" + TERM)\n",
    "        print(\"Fold: {}\".format(fold))\n",
    "        print(\"Fold took: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds to train\")\n",
    "        print(\"Last val: {}\".format(loss))\n",
    "        print(\"Best val: {}\".format(best_val))\n",
    "        print()\n",
    "        print(\"Precision: {}\".format(mean_precision))\n",
    "        print(\"90% CI: {}\".format(np.percentile(precisions, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(precisions), np.max(precisions))\n",
    "        print()\n",
    "\n",
    "        print(\"Recall: {}\".format(mean_recall))\n",
    "        print(\"90% CI: {}\".format(np.percentile(recalls, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(recalls), np.max(recalls))\n",
    "        print()\n",
    "\n",
    "        print(\"F1/Dice score: {}\".format(mean_f1))\n",
    "        print(\"90% CI: {}\".format(np.percentile(F1s, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(F1s), np.max(F1s))\n",
    "        print()\n",
    "\n",
    "        print(\"IoU: {}\".format(mean_IOU))\n",
    "        print(\"90% CI: {}\".format(np.percentile(IOUs, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(IOUs), np.max(IOUs))\n",
    "        print()\n",
    "        print(\"--------------------\")\n",
    "        \n",
    "    \"\"\"Fold loop end\"\"\"\n",
    "    print()\n",
    "    print(\"ALL FOLDS TRAINING ENDED\")\n",
    "    print(\"Mean best validation: {}\".format(np.mean(fold_validation)))\n",
    "    print(\"Mean precision: {}\".format(np.mean(fold_precision)))\n",
    "    print(\"Mean recall: {}\".format(np.mean(fold_recall)))\n",
    "    print(\"Mean F1: {}\".format(np.mean(fold_f1)))\n",
    "    print(\"Mean IOU: {}\".format(np.mean(fold_IOU)))\n",
    "\"\"\"term loop end\"\"\"\n",
    "print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d558cb-b745-4eb1-99e6-a04f6c1d253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
