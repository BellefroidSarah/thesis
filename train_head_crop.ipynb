{
 "cells": [
  {
   "cell_type": "raw",
   "id": "30729826-0e1f-4538-890c-826332a10138",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on October 29, 2022\n",
    "\n",
    "The following things are implemented:\n",
    "    - Kfold cross validation avg\n",
    "    \n",
    "To implement:\n",
    "    - Stop training when no improvement\n",
    "    - Use network to crop the fish out (will need to change dataset.py, transform fct will be different for every img)\n",
    "    \n",
    "Things to think about:\n",
    "    - Decrease LR \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db6b7f3-c1ef-44f5-9e24-1a3ab9a6625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import random\n",
    "import dataset\n",
    "import metrics\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import constants as cst\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import loss_fn_v2 as loss_fn\n",
    "import torchvision.transforms.functional as FF\n",
    "\n",
    "from unet import UNET\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981836a3-16e4-4e12-9ef3-b60da9526b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def validate(model, validation_loader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for images, masks, _, _ in validation_loader:\n",
    "            outputs = model(images.to(DEVICE))\n",
    "\n",
    "            masks = masks.type(torch.LongTensor)\n",
    "            masks = torch.squeeze(masks, 1)\n",
    "\n",
    "            vloss = criterion(outputs, masks.to(DEVICE))\n",
    "            loss = vloss.detach().item()\n",
    "            val_loss.append(loss)\n",
    "\n",
    "        loss = np.mean(val_loss)\n",
    "        # print(\"Validation loss before training: {}\".format(loss))\n",
    "    return loss\n",
    "\n",
    "def train(model, training_loader, criterion, optimiser):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for images, masks, _, _ in training_loader:\n",
    "        outputs = model(images.to(DEVICE))\n",
    "\n",
    "        masks = masks.type(torch.LongTensor)\n",
    "        masks = torch.squeeze(masks, 1)\n",
    "\n",
    "        tloss = criterion(outputs, masks.to(DEVICE))\n",
    "        loss = tloss.detach().item()\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        tloss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    loss = np.mean(train_loss)\n",
    "    return loss\n",
    "\n",
    "def evaluate(eval_model, testing_loader):\n",
    "    tps = 0\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    F1s = []\n",
    "    IOUs = []\n",
    "    \n",
    "    eval_model.eval()\n",
    "    for image, mask, name, size in testing_loader:\n",
    "        h_length = int(size[0])\n",
    "        v_length = int(size[1])\n",
    "        if h_length>v_length:\n",
    "            untr = transforms.Compose([transforms.Resize((h_length, h_length)),\n",
    "                                       transforms.CenterCrop((v_length, h_length))])\n",
    "        elif h_length<v_length:\n",
    "            untr = transforms.Compose([transforms.Resize((v_length, v_length)),\n",
    "                                       transforms.CenterCrop((v_length, h_length))])\n",
    "        else:\n",
    "            untr = transforms.Compose([transforms.Resize((h_length, h_length))])\n",
    "\n",
    "        image_name = name[0]\n",
    "        \n",
    "        prediction = utils.predict_img(eval_model, image, DEVICE, untr, out_threshold=cst.THRESHOLD)\n",
    "        pred = torch.from_numpy(prediction)\n",
    "        \"\"\"pr = pred * 1\n",
    "        pr = pr.unsqueeze(dim=0)\n",
    "        show_images(pr)\"\"\"\n",
    "\n",
    "        mask = untr(mask)\n",
    "\n",
    "        precisions.append(metrics.precision(pred, mask))\n",
    "        recalls.append(metrics.recall(pred, mask))\n",
    "        F1s.append(metrics.F1Score(pred, mask))\n",
    "        IOUs.append(metrics.IOUScore(pred, mask))\n",
    "    return precisions, recalls, F1s, IOUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0dfda9-ebcf-4005-8b56-e4fa3e006535",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cst.SEED)\n",
    "torch.manual_seed(cst.SEED)\n",
    "np.random.seed(cst.SEED)\n",
    "\n",
    "DEVICE_NAME = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE_NAME = 'cuda:0'\n",
    "DEVICE = torch.device(DEVICE_NAME)\n",
    "\n",
    "# Model used to first crop the fish out of the image\n",
    "model_name = \"fish_CE_Fold_4_Epoch_95_MaxEpochs_600_Adam_LR_0.0001.pth\"\n",
    "model_path = os.path.join(cst.MODEL, model_name)\n",
    "\n",
    "fish_model = utils.load_model(model_path)\n",
    "fish_model.to(DEVICE)\n",
    "\n",
    "TERMS = [\"p\"]\n",
    "SIZE = (384, 512)\n",
    "FOLDS = [4]    # 0 to 4 only a few folds at a time here for computational resources limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3787354-d69c-4cde-96ef-19a253735f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting term: p\n",
      "Starting fold: 4\n",
      "Training set length: 84\n",
      "Validation set length: 20\n",
      "Testing set length: 20\n",
      "Loss used: Tversky\n",
      "Epoch: 50\n",
      "Validation: 0.028231489658355712.\n",
      "Best: 0.028231489658355712.\n",
      "Epoch: 100\n",
      "Validation: 0.0110921710729599.\n",
      "Best: 0.0110921710729599.\n",
      "Epoch: 150\n",
      "Validation: 0.007266291975975036.\n",
      "Best: 0.007266291975975036.\n",
      "Epoch: 200\n",
      "Validation: 0.006193614006042481.\n",
      "Best: 0.0061792820692062374.\n",
      "Epoch: 250\n",
      "Validation: 0.005617296695709229.\n",
      "Best: 0.005565047264099121.\n",
      "Epoch: 300\n",
      "Validation: 0.005323374271392822.\n",
      "Best: 0.0052580684423446655.\n",
      "Epoch: 350\n",
      "Validation: 0.005260872840881348.\n",
      "Best: 0.005170685052871704.\n",
      "Epoch: 400\n",
      "Validation: 0.005530166625976563.\n",
      "Best: 0.0050184279680252075.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last epoch: 434\n",
      "Term: p\n",
      "Fold: 4\n",
      "Fold took: 318.0 minutes 38.2128746509552 seconds to train\n",
      "Last val: 0.005345931649208069\n",
      "Best val: 0.0050184279680252075\n",
      "\n",
      "Precision: 0.9803494688810176\n",
      "90% CI: [0.91980027 1.        ]\n",
      "Min, max: 0.8439823649398933 0.9999999999996522\n",
      "\n",
      "Recall: 0.7055495690905732\n",
      "90% CI: [0.61456104 0.80563907]\n",
      "Min, max: 0.44705962614261907 0.8264707777557662\n",
      "\n",
      "F1/Dice score: 0.8168249900671825\n",
      "90% CI: [0.75768887 0.85853171]\n",
      "Min, max: 0.6178481072331163 0.8882170116495998\n",
      "\n",
      "IoU: 0.6934927664059247\n",
      "90% CI: [0.61087342 0.75219322]\n",
      "Min, max: 0.4470189640273667 0.7989122166435422\n",
      "\n",
      "--------------------\n",
      "\n",
      "ALL FOLDS TRAINING ENDED\n",
      "Mean best validation: 0.0050184279680252075\n",
      "Mean precision: 0.9803494688810176\n",
      "Mean recall: 0.7055495690905732\n",
      "Mean F1: 0.8168249900671825\n",
      "Mean IOU: 0.6934927664059247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for TERM in TERMS:\n",
    "    print(\"Starting term: \" + TERM)\n",
    "    start_term = time.time()\n",
    "    \n",
    "    image_folder = \"/notebooks/images\"\n",
    "    mask_folder = \"/notebooks/\" + TERM\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(SIZE),\n",
    "                                    transforms.Pad((0, 64, 0, 64))])\n",
    "    untransform = transforms.Compose([transforms.CenterCrop(SIZE),\n",
    "                                     transforms.Resize((1932, 2576))])\n",
    "    \n",
    "    fold_validation = []\n",
    "    fold_precision = []\n",
    "    fold_recall = []\n",
    "    fold_f1 = []\n",
    "    fold_IOU = []\n",
    "    \n",
    "    for fold in FOLDS:\n",
    "        print(\"Starting fold: {}\".format(fold))\n",
    "        start_fold = time.time()\n",
    "        \"\"\"Datasets and loaders\"\"\"\n",
    "        training_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"train\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "\n",
    "        validation_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"validate\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "        \n",
    "        testing_set = dataset.ZebrafishDataset_KFold_crop_head(image_folder,\n",
    "                                                           mask_folder,\n",
    "                                                           actual_fold=fold,\n",
    "                                                           model = fish_model,\n",
    "                                                           device = DEVICE,\n",
    "                                                           dataset=\"test\",\n",
    "                                                           folds = cst.FOLDS)\n",
    "\n",
    "        training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                                      batch_size=cst.BATCH_SIZE,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=cst.WORKERS)\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                        batch_size=cst.BATCH_SIZE,\n",
    "                                                        shuffle=True,\n",
    "                                                        num_workers=cst.WORKERS)\n",
    "\n",
    "        testing_loader = torch.utils.data.DataLoader(testing_set,\n",
    "                                                     batch_size=1,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=cst.WORKERS)\n",
    "        \n",
    "        \n",
    "        model = UNET(3, 2)\n",
    "        model.to(DEVICE)\n",
    "        best_model = UNET(3, 2)\n",
    "        best_model = model\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion_string = \"CE\"\n",
    "\n",
    "        if cst.LOSS == \"Dice\":\n",
    "            print(\"Loss used: Dice\")\n",
    "            criterion = loss_fn.DiceLoss()\n",
    "            criterion_string = \"DCE\"\n",
    "        if cst.LOSS == \"IOU\":\n",
    "            print(\"Loss used: IOU\")\n",
    "            criterion = loss_fn.IoULoss()\n",
    "            criterion_string = \"IOU\"\n",
    "        if cst.LOSS == \"Tversky\":\n",
    "            print(\"Loss used: Tversky\")\n",
    "            criterion = loss_fn.TverskyLoss(alpha=0.7, beta= 0.3)\n",
    "            criterion_string = \"Tversky\"\n",
    "        if cst.LOSS == \"Focal\":\n",
    "            print(\"Loss used: Focal\")\n",
    "            criterion = loss_fn.FocalLoss(alpha=0.8, gamma= 2, reduction=\"mean\")\n",
    "            criterion_string = \"Focal\"\n",
    "\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=cst.LEARNING_RATE, weight_decay=cst.WEIGHT_DECAY)\n",
    "        optimiser_string = \"ADAM\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        if cst.OPTIMIZER == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                        lr=cst.LEARNING_RATE,\n",
    "                                        momentum=cst.MOMENTUM,\n",
    "                                        weight_decay=cst.WEIGHT_DECAY)\n",
    "            optimiser_string = \"SGD\" + \"_\" + \"LR\" + str(cst.LEARNING_RATE) + \"_\" + \"M\" + str(cst.MOMENTUM)\n",
    "            optimiser_string += \"_\" + \"WD\" + str(cst.WEIGHT_DECAY)\n",
    "        \n",
    "        params_string = \"Params\" + \"_\" + \"Epoch\" + str(cst.EPOCHS) + \"_\" + \"BS\" + str(cst.BATCH_SIZE)\n",
    "        params_string += \"_\" + \"W\" + str(cst.WORKERS)\n",
    "        \n",
    "        \"\"\"Computing validation loss before training\"\"\"\n",
    "        loss = validate(model, validation_loader, criterion)\n",
    "            \n",
    "        best_val = loss\n",
    "        best_epoch = 0\n",
    "        last_epoch = 0\n",
    "        \n",
    "        epochs_train_losses = []\n",
    "        epochs_val_losses = []\n",
    "        for epoch in range(cst.EPOCHS):\n",
    "            \"\"\" Training \"\"\"\n",
    "            loss = train(model, training_loader, criterion, optimiser)\n",
    "            epochs_train_losses.append(loss)\n",
    "\n",
    "            \"\"\" Validation \"\"\"\n",
    "            loss = validate(model, validation_loader, criterion)\n",
    "            epochs_val_losses.append(loss)\n",
    "            \n",
    "            # Updating best model\n",
    "            if loss < best_val:\n",
    "                best_val = loss\n",
    "                best_model = model\n",
    "                best_epoch = epoch+1\n",
    "            \n",
    "            if (epoch+1)%50 == 0:\n",
    "                print(\"Epoch: \" + str(epoch+1))\n",
    "                print(\"Validation: {}.\".format(loss))\n",
    "                print(\"Best: {}.\".format(best_val))\n",
    "                    \n",
    "            \"\"\"Train and validate loops over\"\"\"\n",
    "            curr = time.time()\n",
    "            curr = curr - start_term\n",
    "            secondes = curr % 60\n",
    "            minutes = (curr-secondes)/60\n",
    "            \n",
    "            last_epoch = epoch\n",
    "            \n",
    "            # Notebooks shutdown after 6 hours. Stop the code and save the results.\n",
    "            if minutes >= 345:\n",
    "                break\n",
    "            if (epoch - best_epoch) >= 50:\n",
    "                break\n",
    "            \n",
    "        \"\"\"All epochs are over\"\"\" \n",
    "        fold_validation.append(best_val)\n",
    "        \n",
    "        model_name = TERM + '_head_crop_k5_' + cst.LOSS + \"_Fold_\" + str(fold) + \"_Epoch_\" + str(best_epoch) + \"_MaxEpochs_\" \n",
    "        model_name += str(cst.EPOCHS) + '_' + cst.OPTIMIZER + \"_LR_\" + str(cst.LEARNING_RATE) + \".pth\"\n",
    "        \n",
    "        model_filepath = os.path.join(cst.MODEL, model_name)\n",
    "        torch.save(best_model.state_dict(), model_filepath)\n",
    "        \n",
    "        index = [i+1 for i in range(last_epoch+1)]\n",
    "        plt.plot(index[1:], epochs_train_losses[1:], label=\"Training\")\n",
    "        plt.plot(index[1:], epochs_val_losses[1:], label=\"Validation\")\n",
    "        plt.title(str(cst.LOSS) + \" Fold \" + str(fold)) \n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\"Evaluating\"\"\"\n",
    "        precisions, recalls, F1s, IOUs = evaluate(best_model, testing_loader)\n",
    "        \n",
    "        mean_precision = np.mean(precisions)\n",
    "        mean_recall = np.mean(recalls)\n",
    "        mean_f1 = np.mean(F1s)\n",
    "        mean_IOU = np.mean(IOUs)\n",
    "        \n",
    "        fold_precision.append(mean_precision)\n",
    "        fold_recall.append(mean_recall)\n",
    "        fold_f1.append(mean_f1)\n",
    "        fold_IOU.append(mean_IOU)\n",
    "        \n",
    "        confidence = 0.9\n",
    "        \n",
    "        curr = time.time()\n",
    "        curr = curr - start_fold\n",
    "        secondes = curr % 60\n",
    "        minutes = (curr-secondes)/60\n",
    "        \n",
    "        #print(\"--------------------\")\n",
    "        print(\"Last epoch: {}\".format(last_epoch))\n",
    "        print(\"Term: \" + TERM)\n",
    "        print(\"Fold: {}\".format(fold))\n",
    "        print(\"Fold took: \" + str(minutes) + \" minutes \" + str(secondes) + \" seconds to train\")\n",
    "        print(\"Last val: {}\".format(loss))\n",
    "        print(\"Best val: {}\".format(best_val))\n",
    "        print()\n",
    "        print(\"Precision: {}\".format(mean_precision))\n",
    "        print(\"90% CI: {}\".format(np.percentile(precisions, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(precisions), np.max(precisions))\n",
    "        print()\n",
    "\n",
    "        print(\"Recall: {}\".format(mean_recall))\n",
    "        print(\"90% CI: {}\".format(np.percentile(recalls, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(recalls), np.max(recalls))\n",
    "        print()\n",
    "\n",
    "        print(\"F1/Dice score: {}\".format(mean_f1))\n",
    "        print(\"90% CI: {}\".format(np.percentile(F1s, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(F1s), np.max(F1s))\n",
    "        print()\n",
    "\n",
    "        print(\"IoU: {}\".format(mean_IOU))\n",
    "        print(\"90% CI: {}\".format(np.percentile(IOUs, [100*(1-confidence)/2,100*(1-(1-confidence)/2)])))\n",
    "        print(\"Min, max:\", np.min(IOUs), np.max(IOUs))\n",
    "        print()\n",
    "        print(\"--------------------\")\n",
    "        \n",
    "    \"\"\"Fold loop end\"\"\"\n",
    "    print()\n",
    "    print(\"ALL FOLDS TRAINING ENDED\")\n",
    "    print(\"Mean best validation: {}\".format(np.mean(fold_validation)))\n",
    "    print(\"Mean precision: {}\".format(np.mean(fold_precision)))\n",
    "    print(\"Mean recall: {}\".format(np.mean(fold_recall)))\n",
    "    print(\"Mean F1: {}\".format(np.mean(fold_f1)))\n",
    "    print(\"Mean IOU: {}\".format(np.mean(fold_IOU)))\n",
    "\"\"\"term loop end\"\"\"\n",
    "print()    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
